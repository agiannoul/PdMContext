<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>PdmContext.ContextGeneration API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>PdmContext.ContextGeneration</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import numpy as np
import statistics

import pandas as pd
from PdmContext.utils.structure import Eventpoint,Context
from PdmContext.utils.causal_discovery_functions import calculatewithPc
from PdmContext.utils.showcontext import show_Context_list



class ContextGenerator:

    def __init__(self,target,context_horizon=&#34;8&#34;,Causalityfunct=calculatewithPc,debug=False):
        &#34;&#34;&#34;
        This Class handle the Context Generation. It keeps an internal buffer to build the context for a target series based
        on the provided context_horizon. All data are passed though the collect_data method, which return a correspoding
        Context when target data are passed.


        **Parameters**:

        **target**: The name of the target source, which will be used as the baseline in order to map different samples
         rate to that of the target sample rate.

        **context_horizon**: The time period to look back for context data, the form of that parameter is &#34;8 hours&#34;

        **Causalityfunct**: the causality discovery method to use to produce causal relationships between context data,
            This must be a function with parameters two equal size lists, one with names and the other
            with data (a list of list or 2D numpy array).

        **debug**: If it runs on debug mode
        &#34;&#34;&#34;


        self.debug=debug
        self.target=target


        self.contexts=[]

        self.causality_discovery=Causalityfunct
        self.buffer=[]


        #helpers
        self.type_of_series = {}
        self.horizon = context_horizon.split(&#34; &#34;)[0]
        if len(context_horizon.split(&#34; &#34;)) == 1:
            self.horizon_time = &#34;hours&#34;
        else:
            if context_horizon.split(&#34; &#34;)[1] in [&#34;days&#34;, &#34;hours&#34;, &#34;minutes&#34;, &#34;seconds&#34;]:
                self.horizon_time = context_horizon.split(&#34; &#34;)[1]
            else:
                assert False, &#34;Time horizon must be either a single number or in form of \&#34;8 hours\&#34; where acceptable time frames are hours,days,minutes,seconds&#34;

        self.horizon = int(self.horizon)
        self.interpret_history_pos = 0
        self.context_pos = 0
    def collect_data(self,timestamp,source,name,value=None,type=&#34;Univariate&#34;):
        &#39;&#39;&#39;
        This method is used when data are passed iteratively, and stored in buffer
        When data of target source arrive, a corresponding context is produced.
        Sources can be of different sample rate (all sources are mapped to the targets sample rate when context is produced)

        Sources can be of either:

        1) Continuous type (those that have some kind of arithmetic value)

        2) Discrete events (without value) , where one of the type isolated or configuration must be assigned
            A guide on how to specify the type is, that events which assumed to have impact only on their occurrence, are called
            isolated, while others that are related to some kind of configuration with more permanent impact, are called configuration.
            Essentially the type of the events define the way that will be transformed to real values time-series.

        **Parameters**:

        **timestamp**:  The timestamp of the arrived value

        **source**: The source of the arrived value

        **name**: The name (or identifier) of the arrived value

        **value**: The value (float), in case this is None the arrived data is considered as event

        **type**: the type of the data can be one of &#34;isolated&#34;,&#34;configuration&#34; when no value is passed

        **return**:  structure.Context object when the data name match to the target name or None.
        &#39;&#39;&#39;

        if value is None:
            if type not in [&#34;isolated&#34;,&#34;configuration&#34;]:
                assert False,&#34;The type must be defined as one of \&#34;isolated\&#34; and \&#34;configuration\&#34; when no value is passed&#34;
        eventpoint=Eventpoint(code=name,source=source,timestamp=timestamp,details=value,type=type)
        self.add_to_buffer(eventpoint)
        if self.target == name or self.target == f&#34;{name}@{source}&#34;:
            contextobject=self.generate_context(e=eventpoint,buffer=self.buffer)
            return contextobject
        else:
            return None
    def add_to_buffer(self,e: Eventpoint):
        index = len(self.buffer)
        for i in range(len(self.buffer) - 1, 0, -1):
            if self.buffer[i].timestamp &lt;= e.timestamp:
                index = i + 1
                break
        if index == len(self.buffer):
            self.buffer.append(e)
        else:
            self.buffer = self.buffer[: index] + [e] + self.buffer[index:]

        last=self.buffer[-1]
        pos=len(self.buffer)-1
        for i in range(len(self.buffer)):
            if self.buffer[i].timestamp&gt;=(last.timestamp-pd.Timedelta(self.horizon, self.horizon_time)):
                pos=i
                break
        self.buffer=self.buffer[pos:]

    def generate_context(self,e:Eventpoint,buffer):
        contextcurrent, target_series_name = self.create_context(e,buffer)

        self.contexts.append(contextcurrent)
        self.create_interpertation(contextcurrent, target_series_name)


        intertups = [tttup for tttup in
                     self.contexts[-1].CR[&#34;interpertation&#34;]]
        # this is usefull for ploting
        self.contexts[-1].CR[&#34;interpertation&#34;] = intertups

        return self.contexts[-1]

    def create_interpertation(self,contextcurrent :Context,target_series_name):
        rikicontext=self.contexts
        pos=self.interpret_history_pos
        temppos=pos
        for q in range(pos,len(rikicontext)):
            temppos=q
            if pd.to_datetime(rikicontext[q].timestamp) &gt;= (pd.to_datetime(contextcurrent.timestamp) - pd.Timedelta(self.horizon, self.horizon_time)):
                break
        causeswindow = rikicontext[temppos:]
        self.interpret_history_pos=temppos
        interpr=self.interpret(contextcurrent,causeswindow,target_series_name,self.type_of_series)
        self.contexts[-1].CR[&#34;interpertation&#34;]=interpr

    def interpret(self,context : Context, causeswindow, target, type_of_series):
        pairs = [(pair[0], pair[1], car) for pair, car in zip(context.CR[&#39;edges&#39;], context.CR[&#39;characterization&#39;]) if
                 target in pair[1]]
        interpretation = []
        if len(pairs) == 0:
            return []
        for pair in pairs:
            if type_of_series[pair[0]] == &#34;isolated&#34;:
                values1 = context.CD[pair[0]]
                if values1[-1] == 1:
                    interpretation.append(pair)
                elif values1[-2] == 1:
                    interpretation.append(pair)
            elif type_of_series[pair[0]] == &#34;configuration&#34;:
                if pair[0] == &#34;weld@press&#34; and pair[2] == &#34;increase&#34;:
                    ok = &#34;ok&#34;
                values1 = context.CD[pair[0]]
                occurence = 0
                for q in range(len(values1)):
                    if values1[q] == values1[-1] and values1[q] &gt; 0:
                        occurence = q
                        break
                if occurence == len(values1) - 1:
                    interpretation.append(pair)
                else:
                    lead = len(values1) - occurence
                    counter = 0
                    leadcontext = causeswindow[-lead:]
                    for conte in leadcontext:
                        try:
                            pos = list(conte.CR[&#34;edges&#34;]).index((pair[0], pair[1]))
                        except:
                            pos = -1
                        if pos != -1:
                            if conte.CR[&#34;characterization&#34;][pos] == pair[2]:
                                counter += 1
                    if counter &gt;= 0.8 * lead:
                        interpretation.append(pair)
            # for real value series
            if len(set(context.CD[pair[0]])) &gt; 2:
                interpretation.append(pair)
                continue
        # check target -&gt; isolated
        pairs = [(pair[0], pair[1], car) for pair, car in zip(context.CR[&#39;edges&#39;], context.CR[&#39;characterization&#39;]) if
                 target in pair[0] and type_of_series[pair[1]] == &#34;isolated&#34;]
        # for pair in pairs:
        #     if type_of_series[pair[1]] == &#34;isolated&#34;:
        #         values1 = context.CD[pair[1]]
        #         if values1[-1] == 1 or values1[-2] == 1:
        #             interpretation.append((pair[1],pair[0],pair[2]))
        return list(set(interpretation))
    def create_context(self,current :Eventpoint,buffer):

        #start = time.time()
        # df with ,dt,code,source,value
        pos=self.context_pos
        for i in range(pos,len(buffer)):
            if buffer[i].timestamp&lt;=(current.timestamp-pd.Timedelta(self.horizon, self.horizon_time)):
                pos=i
            else:
                break

        self.context_pos=pos
        #end=time.time()
        #print(f&#34;find position on buffer: {end-start}&#34;)

        #start = time.time()
        dataforcontext=buffer[pos:]
        datatodf=[[pd.to_datetime(e.timestamp) for e in dataforcontext],
                [str(e.code) for e in dataforcontext],
                [str(e.source) for e in dataforcontext],
                [e.details for e in dataforcontext],
                [e.type for e in dataforcontext]]

        npcontext=np.array(datatodf)
        npcontext=npcontext.T

        npcontext=self.Numpy_preproccess(npcontext)

        #end = time.time()
        #print(f&#34;preprocess df: {end - start}&#34;)
        ############# create context ############################
        #start = time.time()
        ## collect uniqeu data series
        #allcodes = df[&#39;code&#39;].unique()
        allcodes = np.unique(npcontext[:,1])
        allcodes = [code for code in allcodes]
        allcodes = set(allcodes)

        for uncode in allcodes:
            for qq in range(len(npcontext)):
                if uncode in npcontext[qq][1]:
                    self.type_of_series[uncode]=npcontext[qq][4]
                    break


        ## build target series
        target_series_name,target_series=self.build_target_series_for_context(current,npcontext)

        ## create series for each source (alldata)
        alldata=self.create_contius_representation(target_series_name,target_series,npcontext,self.type_of_series,allcodes)
        #end = time.time()
        #print(f&#34;Create series: {end-start}&#34;)

        storing = self.calculate_edges(alldata, current.timestamp)
        storing[&#34;characterization&#34;]=self.getcaracterize(storing)

        #print(f&#34;Calculate edges: {end - start}&#34;)
        # print(&#34;========================&#34;)


        contextpbject=Context.ContextFromDict(storing)
        return contextpbject,target_series_name

    def getcaracterize(self,context):
        edges = context[&#34;edges&#34;]
        characterizations = []
        for edge in edges:
            name1 = edge[0]
            name2 = edge[1]
            values1 = context[name1]
            values2 = [float(kati) for kati in context[name2]]

            occurence=len(values1)-1
            for i in range(len(values1)-2,0,-1):
                if values1[i] != values1[-1]:
                    occurence = i+1
                    break
            previusoccurence = 0
            for i in range(occurence-2,0,-1):
                if values1[i] !=  values1[occurence-1]:
                    previusoccurence = i

            if occurence - previusoccurence &lt; 2:  # or len(values2)-occurence&lt;2:
                characterizations.append(&#34;uknown&#34;)
                continue
            values2before = values2[previusoccurence:occurence]
            # stdv = statistics.stdev(values2before)
            # mean = statistics.stdev(values2before)
            # values2before=[v if v&lt;mean+5*stdv else mean for v in values2before]

            # values2after=values2[occurence:]
            values2after = [values2[-1]]
            # stdv = statistics.stdev(values2after)
            # mean = statistics.stdev(values2after)
            # values2after = [v if v &lt; mean + 3 * stdv else mean for v in values2after]

            stdv = statistics.stdev(values2before)
            if len(values2before) == 0:
                char = &#34;uknown&#34;
            elif statistics.median(values2before) - statistics.median(values2after) &gt; 2 * stdv:
                char = &#34;decrease&#34;
            elif statistics.median(values2after) - statistics.median(values2before) &gt; 2 * stdv:
                char = &#34;increase&#34;
            else:
                char = &#34;uknown&#34;
            characterizations.append(char)
        return characterizations

    def calculate_edges(self,alldata, timestamp):
        #start = time.time()
        storing = {}
        storing[&#34;timestamp&#34;] = timestamp

        alldata_names = [nn[0] for nn in alldata]
        alldata_data = [nn[1] for nn in alldata]

        for namedd, datadd in zip(alldata_names, alldata_data):
            storing[namedd] = datadd

        # For context with more than two series calculate PC casualities
        count = len([1 for lista in alldata_data if lista is not None])
        if count &gt; 1 and len(alldata[0][1]) &gt; 5:
            alldata_names = [nn[0] for nn in alldata if nn[1] is not None and len(set(nn[1]))&gt;1]
            alldata_data = [nn[1] for nn in alldata if nn[1] is not None and len(set(nn[1]))&gt;1]

            #end = time.time()
            #print(f&#34;before {end - start}&#34;)
            #start=time.time()

            edges = self.calculate_causality(np.column_stack(alldata_data), alldata_names)
            #end=time.time()
            #print(f&#34;actual edge calculation {end-start}&#34;)
            if edges is None:
                singleedges = []
            else:
                singleedges = edges
            # print(edges)
            storing[&#34;edges&#34;] = singleedges
            return storing
        storing[&#34;edges&#34;] = []
        return storing

    def create_contius_representation(self,target_series_name,target_series,df,type_of_series,allcodes):
        # if len(target_series) &lt; 5:
        #     alldata = []
        #     padding=[0 for q in range(5-len(target_series))]
        #     padding.extend([tags[0] for tags in target_series])
        #     alldata.append((target_series_name, padding))
        #     return alldata
        windowvalues = df#.values
        alldata = []
        alldata.append((target_series_name, [tag[0] for tag in target_series]))
        for name in allcodes:
            # already calculated in targetseries.
            if target_series_name in name:
                continue

            # detect the occurancies
            occurencies = [(value, time) for code, value, time in
                           zip(windowvalues[:, 1], windowvalues[:, 3], windowvalues[:, 0]) if name in code]

            vector = [0 for i in range(len(target_series))]
            if len(occurencies) == 0:
                vector = [0 for i in range(len(target_series))]
            elif occurencies[0][0] is not None:
                vector = self.buildcontextforUnivariate(target_series, occurencies)
            elif type_of_series[name] == &#34;isolated&#34;:
                vector = self.buildcontextforisolated(target_series, occurencies)
            elif type_of_series[name] == &#34;configuration&#34;:
                vector = self.buildcontextforCOnfiuguration(target_series, occurencies)

            ok = &#34;ok&#34;
            # if vector is stationary then no context.
            if max(vector) == 0 and min(vector) == 0:
                vector = None
            alldata.append((name, vector))
        return alldata

    def build_target_series_for_context(self,current : Eventpoint,df : pd.DataFrame):
        target_series_name = current.code
        windowvalues = df#.values
        target_series = [(value, time) for code, value, time in
                         zip(windowvalues[:, 1], windowvalues[:, 3], windowvalues[:, 0]) if target_series_name in code]

        return target_series_name,target_series

    def Numpy_preproccess(self,npcontext):
        npcontext = np.where(npcontext == &#34;nan&#34;, None, npcontext)

        mask = [(&#39;0_&#39; in code and value is None)for code,value in zip(npcontext[:,1],npcontext[:,3])]

        # if isinstance(mask,collections.abc.Sequence)==False:
        #     mask=[mask]
        npcontext[mask, 3] = 0
        mask = [(&#39;1_&#39; in code and value is None)for code,value in zip(npcontext[:,1],npcontext[:,3])]
        npcontext[mask, 3] = 1
        code_with_source = [f&#34;{code}{source}&#34; if source[0]==&#34;@&#34; else  f&#34;{code}@{source}&#34; for code, source in zip(npcontext[:,1], npcontext[:,2])]
        npcontext[:,1] = code_with_source


        return npcontext

    def buildcontextforCOnfiuguration(self,target_series, occurencies):
        vector = [0 for i in range(len(target_series))]
        for occ in occurencies:
            for q in range(len(target_series)):
                if target_series[q][1] &gt;= occ[1]:
                    for k in range(q, len(vector)):
                        vector[k] += 1
                    break
        ## not stable
        if len(set(vector))==1:
            vector[0]=0
        return vector

    def buildcontextforisolated(self,target_series, occurencies):
        vector = [0 for i in range(len(target_series))]
        for occ in occurencies:
            for q in range(len(target_series)):
                if target_series[q][1] &gt; occ[1]:
                    vector[q] = 1
                    break
        return vector

    def buildcontextforUnivariate(self,target_series, occurencies):
        allvalues=[]
        vector = [0 for i in range(len(target_series))]
        pos = 0
        for i in range(len(target_series)):
            timestamp = target_series[i][1]
            current_pos = pos
            for q in range(pos, len(occurencies)):
                if occurencies[q][1] &gt; timestamp:
                    current_pos = q
                    break
            # no data found

            if current_pos == pos:
                # if no data in betwwen values use the previus value
                if i &gt; 0:
                    vector[i] = vector[i - 1]
                # if no data until i timestamp use the first occurence as value
                else:
                    vector[i] = occurencies[0][0]
            # if multiple values in between two timestamps use the mean of them as value
            else:
                dataInBetween = [value for value, time in occurencies[pos:current_pos]]
                vector[i] = sum(dataInBetween) / len(dataInBetween)
            # if no other occurencies just repeat the last value
            if current_pos == len(occurencies):
                for k in range(i + 1, len(vector)):
                    vector[k] = vector[k - 1]
                break
            pos = current_pos

        return vector

    def calculate_causality(self,dataor, names):
        num_time_series = len(dataor)
        data = np.array(dataor)
        edges=self.causality_discovery(names,data)
        #edges=self.calculatewithPc(names,data)
        #edges=self.calculatewith_fci(names,data)
        #edges=self.salesforcePC(names,data)
        return edges

    def plot(self,filteredges=[[&#34;&#34;, &#34;&#34;, &#34;&#34;]]):
        show_Context_list(self.contexts,self.target,filteredges=filteredges)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="PdmContext.ContextGeneration.ContextGenerator"><code class="flex name class">
<span>class <span class="ident">ContextGenerator</span></span>
<span>(</span><span>target, context_horizon='8', Causalityfunct=&lt;function calculatewithPc&gt;, debug=False)</span>
</code></dt>
<dd>
<div class="desc"><p>This Class handle the Context Generation. It keeps an internal buffer to build the context for a target series based
on the provided context_horizon. All data are passed though the collect_data method, which return a correspoding
Context when target data are passed.</p>
<p><strong>Parameters</strong>:</p>
<p><strong>target</strong>: The name of the target source, which will be used as the baseline in order to map different samples
rate to that of the target sample rate.</p>
<p><strong>context_horizon</strong>: The time period to look back for context data, the form of that parameter is "8 hours"</p>
<p><strong>Causalityfunct</strong>: the causality discovery method to use to produce causal relationships between context data,
This must be a function with parameters two equal size lists, one with names and the other
with data (a list of list or 2D numpy array).</p>
<p><strong>debug</strong>: If it runs on debug mode</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ContextGenerator:

    def __init__(self,target,context_horizon=&#34;8&#34;,Causalityfunct=calculatewithPc,debug=False):
        &#34;&#34;&#34;
        This Class handle the Context Generation. It keeps an internal buffer to build the context for a target series based
        on the provided context_horizon. All data are passed though the collect_data method, which return a correspoding
        Context when target data are passed.


        **Parameters**:

        **target**: The name of the target source, which will be used as the baseline in order to map different samples
         rate to that of the target sample rate.

        **context_horizon**: The time period to look back for context data, the form of that parameter is &#34;8 hours&#34;

        **Causalityfunct**: the causality discovery method to use to produce causal relationships between context data,
            This must be a function with parameters two equal size lists, one with names and the other
            with data (a list of list or 2D numpy array).

        **debug**: If it runs on debug mode
        &#34;&#34;&#34;


        self.debug=debug
        self.target=target


        self.contexts=[]

        self.causality_discovery=Causalityfunct
        self.buffer=[]


        #helpers
        self.type_of_series = {}
        self.horizon = context_horizon.split(&#34; &#34;)[0]
        if len(context_horizon.split(&#34; &#34;)) == 1:
            self.horizon_time = &#34;hours&#34;
        else:
            if context_horizon.split(&#34; &#34;)[1] in [&#34;days&#34;, &#34;hours&#34;, &#34;minutes&#34;, &#34;seconds&#34;]:
                self.horizon_time = context_horizon.split(&#34; &#34;)[1]
            else:
                assert False, &#34;Time horizon must be either a single number or in form of \&#34;8 hours\&#34; where acceptable time frames are hours,days,minutes,seconds&#34;

        self.horizon = int(self.horizon)
        self.interpret_history_pos = 0
        self.context_pos = 0
    def collect_data(self,timestamp,source,name,value=None,type=&#34;Univariate&#34;):
        &#39;&#39;&#39;
        This method is used when data are passed iteratively, and stored in buffer
        When data of target source arrive, a corresponding context is produced.
        Sources can be of different sample rate (all sources are mapped to the targets sample rate when context is produced)

        Sources can be of either:

        1) Continuous type (those that have some kind of arithmetic value)

        2) Discrete events (without value) , where one of the type isolated or configuration must be assigned
            A guide on how to specify the type is, that events which assumed to have impact only on their occurrence, are called
            isolated, while others that are related to some kind of configuration with more permanent impact, are called configuration.
            Essentially the type of the events define the way that will be transformed to real values time-series.

        **Parameters**:

        **timestamp**:  The timestamp of the arrived value

        **source**: The source of the arrived value

        **name**: The name (or identifier) of the arrived value

        **value**: The value (float), in case this is None the arrived data is considered as event

        **type**: the type of the data can be one of &#34;isolated&#34;,&#34;configuration&#34; when no value is passed

        **return**:  structure.Context object when the data name match to the target name or None.
        &#39;&#39;&#39;

        if value is None:
            if type not in [&#34;isolated&#34;,&#34;configuration&#34;]:
                assert False,&#34;The type must be defined as one of \&#34;isolated\&#34; and \&#34;configuration\&#34; when no value is passed&#34;
        eventpoint=Eventpoint(code=name,source=source,timestamp=timestamp,details=value,type=type)
        self.add_to_buffer(eventpoint)
        if self.target == name or self.target == f&#34;{name}@{source}&#34;:
            contextobject=self.generate_context(e=eventpoint,buffer=self.buffer)
            return contextobject
        else:
            return None
    def add_to_buffer(self,e: Eventpoint):
        index = len(self.buffer)
        for i in range(len(self.buffer) - 1, 0, -1):
            if self.buffer[i].timestamp &lt;= e.timestamp:
                index = i + 1
                break
        if index == len(self.buffer):
            self.buffer.append(e)
        else:
            self.buffer = self.buffer[: index] + [e] + self.buffer[index:]

        last=self.buffer[-1]
        pos=len(self.buffer)-1
        for i in range(len(self.buffer)):
            if self.buffer[i].timestamp&gt;=(last.timestamp-pd.Timedelta(self.horizon, self.horizon_time)):
                pos=i
                break
        self.buffer=self.buffer[pos:]

    def generate_context(self,e:Eventpoint,buffer):
        contextcurrent, target_series_name = self.create_context(e,buffer)

        self.contexts.append(contextcurrent)
        self.create_interpertation(contextcurrent, target_series_name)


        intertups = [tttup for tttup in
                     self.contexts[-1].CR[&#34;interpertation&#34;]]
        # this is usefull for ploting
        self.contexts[-1].CR[&#34;interpertation&#34;] = intertups

        return self.contexts[-1]

    def create_interpertation(self,contextcurrent :Context,target_series_name):
        rikicontext=self.contexts
        pos=self.interpret_history_pos
        temppos=pos
        for q in range(pos,len(rikicontext)):
            temppos=q
            if pd.to_datetime(rikicontext[q].timestamp) &gt;= (pd.to_datetime(contextcurrent.timestamp) - pd.Timedelta(self.horizon, self.horizon_time)):
                break
        causeswindow = rikicontext[temppos:]
        self.interpret_history_pos=temppos
        interpr=self.interpret(contextcurrent,causeswindow,target_series_name,self.type_of_series)
        self.contexts[-1].CR[&#34;interpertation&#34;]=interpr

    def interpret(self,context : Context, causeswindow, target, type_of_series):
        pairs = [(pair[0], pair[1], car) for pair, car in zip(context.CR[&#39;edges&#39;], context.CR[&#39;characterization&#39;]) if
                 target in pair[1]]
        interpretation = []
        if len(pairs) == 0:
            return []
        for pair in pairs:
            if type_of_series[pair[0]] == &#34;isolated&#34;:
                values1 = context.CD[pair[0]]
                if values1[-1] == 1:
                    interpretation.append(pair)
                elif values1[-2] == 1:
                    interpretation.append(pair)
            elif type_of_series[pair[0]] == &#34;configuration&#34;:
                if pair[0] == &#34;weld@press&#34; and pair[2] == &#34;increase&#34;:
                    ok = &#34;ok&#34;
                values1 = context.CD[pair[0]]
                occurence = 0
                for q in range(len(values1)):
                    if values1[q] == values1[-1] and values1[q] &gt; 0:
                        occurence = q
                        break
                if occurence == len(values1) - 1:
                    interpretation.append(pair)
                else:
                    lead = len(values1) - occurence
                    counter = 0
                    leadcontext = causeswindow[-lead:]
                    for conte in leadcontext:
                        try:
                            pos = list(conte.CR[&#34;edges&#34;]).index((pair[0], pair[1]))
                        except:
                            pos = -1
                        if pos != -1:
                            if conte.CR[&#34;characterization&#34;][pos] == pair[2]:
                                counter += 1
                    if counter &gt;= 0.8 * lead:
                        interpretation.append(pair)
            # for real value series
            if len(set(context.CD[pair[0]])) &gt; 2:
                interpretation.append(pair)
                continue
        # check target -&gt; isolated
        pairs = [(pair[0], pair[1], car) for pair, car in zip(context.CR[&#39;edges&#39;], context.CR[&#39;characterization&#39;]) if
                 target in pair[0] and type_of_series[pair[1]] == &#34;isolated&#34;]
        # for pair in pairs:
        #     if type_of_series[pair[1]] == &#34;isolated&#34;:
        #         values1 = context.CD[pair[1]]
        #         if values1[-1] == 1 or values1[-2] == 1:
        #             interpretation.append((pair[1],pair[0],pair[2]))
        return list(set(interpretation))
    def create_context(self,current :Eventpoint,buffer):

        #start = time.time()
        # df with ,dt,code,source,value
        pos=self.context_pos
        for i in range(pos,len(buffer)):
            if buffer[i].timestamp&lt;=(current.timestamp-pd.Timedelta(self.horizon, self.horizon_time)):
                pos=i
            else:
                break

        self.context_pos=pos
        #end=time.time()
        #print(f&#34;find position on buffer: {end-start}&#34;)

        #start = time.time()
        dataforcontext=buffer[pos:]
        datatodf=[[pd.to_datetime(e.timestamp) for e in dataforcontext],
                [str(e.code) for e in dataforcontext],
                [str(e.source) for e in dataforcontext],
                [e.details for e in dataforcontext],
                [e.type for e in dataforcontext]]

        npcontext=np.array(datatodf)
        npcontext=npcontext.T

        npcontext=self.Numpy_preproccess(npcontext)

        #end = time.time()
        #print(f&#34;preprocess df: {end - start}&#34;)
        ############# create context ############################
        #start = time.time()
        ## collect uniqeu data series
        #allcodes = df[&#39;code&#39;].unique()
        allcodes = np.unique(npcontext[:,1])
        allcodes = [code for code in allcodes]
        allcodes = set(allcodes)

        for uncode in allcodes:
            for qq in range(len(npcontext)):
                if uncode in npcontext[qq][1]:
                    self.type_of_series[uncode]=npcontext[qq][4]
                    break


        ## build target series
        target_series_name,target_series=self.build_target_series_for_context(current,npcontext)

        ## create series for each source (alldata)
        alldata=self.create_contius_representation(target_series_name,target_series,npcontext,self.type_of_series,allcodes)
        #end = time.time()
        #print(f&#34;Create series: {end-start}&#34;)

        storing = self.calculate_edges(alldata, current.timestamp)
        storing[&#34;characterization&#34;]=self.getcaracterize(storing)

        #print(f&#34;Calculate edges: {end - start}&#34;)
        # print(&#34;========================&#34;)


        contextpbject=Context.ContextFromDict(storing)
        return contextpbject,target_series_name

    def getcaracterize(self,context):
        edges = context[&#34;edges&#34;]
        characterizations = []
        for edge in edges:
            name1 = edge[0]
            name2 = edge[1]
            values1 = context[name1]
            values2 = [float(kati) for kati in context[name2]]

            occurence=len(values1)-1
            for i in range(len(values1)-2,0,-1):
                if values1[i] != values1[-1]:
                    occurence = i+1
                    break
            previusoccurence = 0
            for i in range(occurence-2,0,-1):
                if values1[i] !=  values1[occurence-1]:
                    previusoccurence = i

            if occurence - previusoccurence &lt; 2:  # or len(values2)-occurence&lt;2:
                characterizations.append(&#34;uknown&#34;)
                continue
            values2before = values2[previusoccurence:occurence]
            # stdv = statistics.stdev(values2before)
            # mean = statistics.stdev(values2before)
            # values2before=[v if v&lt;mean+5*stdv else mean for v in values2before]

            # values2after=values2[occurence:]
            values2after = [values2[-1]]
            # stdv = statistics.stdev(values2after)
            # mean = statistics.stdev(values2after)
            # values2after = [v if v &lt; mean + 3 * stdv else mean for v in values2after]

            stdv = statistics.stdev(values2before)
            if len(values2before) == 0:
                char = &#34;uknown&#34;
            elif statistics.median(values2before) - statistics.median(values2after) &gt; 2 * stdv:
                char = &#34;decrease&#34;
            elif statistics.median(values2after) - statistics.median(values2before) &gt; 2 * stdv:
                char = &#34;increase&#34;
            else:
                char = &#34;uknown&#34;
            characterizations.append(char)
        return characterizations

    def calculate_edges(self,alldata, timestamp):
        #start = time.time()
        storing = {}
        storing[&#34;timestamp&#34;] = timestamp

        alldata_names = [nn[0] for nn in alldata]
        alldata_data = [nn[1] for nn in alldata]

        for namedd, datadd in zip(alldata_names, alldata_data):
            storing[namedd] = datadd

        # For context with more than two series calculate PC casualities
        count = len([1 for lista in alldata_data if lista is not None])
        if count &gt; 1 and len(alldata[0][1]) &gt; 5:
            alldata_names = [nn[0] for nn in alldata if nn[1] is not None and len(set(nn[1]))&gt;1]
            alldata_data = [nn[1] for nn in alldata if nn[1] is not None and len(set(nn[1]))&gt;1]

            #end = time.time()
            #print(f&#34;before {end - start}&#34;)
            #start=time.time()

            edges = self.calculate_causality(np.column_stack(alldata_data), alldata_names)
            #end=time.time()
            #print(f&#34;actual edge calculation {end-start}&#34;)
            if edges is None:
                singleedges = []
            else:
                singleedges = edges
            # print(edges)
            storing[&#34;edges&#34;] = singleedges
            return storing
        storing[&#34;edges&#34;] = []
        return storing

    def create_contius_representation(self,target_series_name,target_series,df,type_of_series,allcodes):
        # if len(target_series) &lt; 5:
        #     alldata = []
        #     padding=[0 for q in range(5-len(target_series))]
        #     padding.extend([tags[0] for tags in target_series])
        #     alldata.append((target_series_name, padding))
        #     return alldata
        windowvalues = df#.values
        alldata = []
        alldata.append((target_series_name, [tag[0] for tag in target_series]))
        for name in allcodes:
            # already calculated in targetseries.
            if target_series_name in name:
                continue

            # detect the occurancies
            occurencies = [(value, time) for code, value, time in
                           zip(windowvalues[:, 1], windowvalues[:, 3], windowvalues[:, 0]) if name in code]

            vector = [0 for i in range(len(target_series))]
            if len(occurencies) == 0:
                vector = [0 for i in range(len(target_series))]
            elif occurencies[0][0] is not None:
                vector = self.buildcontextforUnivariate(target_series, occurencies)
            elif type_of_series[name] == &#34;isolated&#34;:
                vector = self.buildcontextforisolated(target_series, occurencies)
            elif type_of_series[name] == &#34;configuration&#34;:
                vector = self.buildcontextforCOnfiuguration(target_series, occurencies)

            ok = &#34;ok&#34;
            # if vector is stationary then no context.
            if max(vector) == 0 and min(vector) == 0:
                vector = None
            alldata.append((name, vector))
        return alldata

    def build_target_series_for_context(self,current : Eventpoint,df : pd.DataFrame):
        target_series_name = current.code
        windowvalues = df#.values
        target_series = [(value, time) for code, value, time in
                         zip(windowvalues[:, 1], windowvalues[:, 3], windowvalues[:, 0]) if target_series_name in code]

        return target_series_name,target_series

    def Numpy_preproccess(self,npcontext):
        npcontext = np.where(npcontext == &#34;nan&#34;, None, npcontext)

        mask = [(&#39;0_&#39; in code and value is None)for code,value in zip(npcontext[:,1],npcontext[:,3])]

        # if isinstance(mask,collections.abc.Sequence)==False:
        #     mask=[mask]
        npcontext[mask, 3] = 0
        mask = [(&#39;1_&#39; in code and value is None)for code,value in zip(npcontext[:,1],npcontext[:,3])]
        npcontext[mask, 3] = 1
        code_with_source = [f&#34;{code}{source}&#34; if source[0]==&#34;@&#34; else  f&#34;{code}@{source}&#34; for code, source in zip(npcontext[:,1], npcontext[:,2])]
        npcontext[:,1] = code_with_source


        return npcontext

    def buildcontextforCOnfiuguration(self,target_series, occurencies):
        vector = [0 for i in range(len(target_series))]
        for occ in occurencies:
            for q in range(len(target_series)):
                if target_series[q][1] &gt;= occ[1]:
                    for k in range(q, len(vector)):
                        vector[k] += 1
                    break
        ## not stable
        if len(set(vector))==1:
            vector[0]=0
        return vector

    def buildcontextforisolated(self,target_series, occurencies):
        vector = [0 for i in range(len(target_series))]
        for occ in occurencies:
            for q in range(len(target_series)):
                if target_series[q][1] &gt; occ[1]:
                    vector[q] = 1
                    break
        return vector

    def buildcontextforUnivariate(self,target_series, occurencies):
        allvalues=[]
        vector = [0 for i in range(len(target_series))]
        pos = 0
        for i in range(len(target_series)):
            timestamp = target_series[i][1]
            current_pos = pos
            for q in range(pos, len(occurencies)):
                if occurencies[q][1] &gt; timestamp:
                    current_pos = q
                    break
            # no data found

            if current_pos == pos:
                # if no data in betwwen values use the previus value
                if i &gt; 0:
                    vector[i] = vector[i - 1]
                # if no data until i timestamp use the first occurence as value
                else:
                    vector[i] = occurencies[0][0]
            # if multiple values in between two timestamps use the mean of them as value
            else:
                dataInBetween = [value for value, time in occurencies[pos:current_pos]]
                vector[i] = sum(dataInBetween) / len(dataInBetween)
            # if no other occurencies just repeat the last value
            if current_pos == len(occurencies):
                for k in range(i + 1, len(vector)):
                    vector[k] = vector[k - 1]
                break
            pos = current_pos

        return vector

    def calculate_causality(self,dataor, names):
        num_time_series = len(dataor)
        data = np.array(dataor)
        edges=self.causality_discovery(names,data)
        #edges=self.calculatewithPc(names,data)
        #edges=self.calculatewith_fci(names,data)
        #edges=self.salesforcePC(names,data)
        return edges

    def plot(self,filteredges=[[&#34;&#34;, &#34;&#34;, &#34;&#34;]]):
        show_Context_list(self.contexts,self.target,filteredges=filteredges)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="PdmContext.ContextGeneration.ContextGenerator.Numpy_preproccess"><code class="name flex">
<span>def <span class="ident">Numpy_preproccess</span></span>(<span>self, npcontext)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def Numpy_preproccess(self,npcontext):
    npcontext = np.where(npcontext == &#34;nan&#34;, None, npcontext)

    mask = [(&#39;0_&#39; in code and value is None)for code,value in zip(npcontext[:,1],npcontext[:,3])]

    # if isinstance(mask,collections.abc.Sequence)==False:
    #     mask=[mask]
    npcontext[mask, 3] = 0
    mask = [(&#39;1_&#39; in code and value is None)for code,value in zip(npcontext[:,1],npcontext[:,3])]
    npcontext[mask, 3] = 1
    code_with_source = [f&#34;{code}{source}&#34; if source[0]==&#34;@&#34; else  f&#34;{code}@{source}&#34; for code, source in zip(npcontext[:,1], npcontext[:,2])]
    npcontext[:,1] = code_with_source


    return npcontext</code></pre>
</details>
</dd>
<dt id="PdmContext.ContextGeneration.ContextGenerator.add_to_buffer"><code class="name flex">
<span>def <span class="ident">add_to_buffer</span></span>(<span>self, e: <a title="PdmContext.utils.structure.Eventpoint" href="utils/structure.html#PdmContext.utils.structure.Eventpoint">Eventpoint</a>)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_to_buffer(self,e: Eventpoint):
    index = len(self.buffer)
    for i in range(len(self.buffer) - 1, 0, -1):
        if self.buffer[i].timestamp &lt;= e.timestamp:
            index = i + 1
            break
    if index == len(self.buffer):
        self.buffer.append(e)
    else:
        self.buffer = self.buffer[: index] + [e] + self.buffer[index:]

    last=self.buffer[-1]
    pos=len(self.buffer)-1
    for i in range(len(self.buffer)):
        if self.buffer[i].timestamp&gt;=(last.timestamp-pd.Timedelta(self.horizon, self.horizon_time)):
            pos=i
            break
    self.buffer=self.buffer[pos:]</code></pre>
</details>
</dd>
<dt id="PdmContext.ContextGeneration.ContextGenerator.build_target_series_for_context"><code class="name flex">
<span>def <span class="ident">build_target_series_for_context</span></span>(<span>self, current: <a title="PdmContext.utils.structure.Eventpoint" href="utils/structure.html#PdmContext.utils.structure.Eventpoint">Eventpoint</a>, df: pandas.core.frame.DataFrame)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def build_target_series_for_context(self,current : Eventpoint,df : pd.DataFrame):
    target_series_name = current.code
    windowvalues = df#.values
    target_series = [(value, time) for code, value, time in
                     zip(windowvalues[:, 1], windowvalues[:, 3], windowvalues[:, 0]) if target_series_name in code]

    return target_series_name,target_series</code></pre>
</details>
</dd>
<dt id="PdmContext.ContextGeneration.ContextGenerator.buildcontextforCOnfiuguration"><code class="name flex">
<span>def <span class="ident">buildcontextforCOnfiuguration</span></span>(<span>self, target_series, occurencies)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def buildcontextforCOnfiuguration(self,target_series, occurencies):
    vector = [0 for i in range(len(target_series))]
    for occ in occurencies:
        for q in range(len(target_series)):
            if target_series[q][1] &gt;= occ[1]:
                for k in range(q, len(vector)):
                    vector[k] += 1
                break
    ## not stable
    if len(set(vector))==1:
        vector[0]=0
    return vector</code></pre>
</details>
</dd>
<dt id="PdmContext.ContextGeneration.ContextGenerator.buildcontextforUnivariate"><code class="name flex">
<span>def <span class="ident">buildcontextforUnivariate</span></span>(<span>self, target_series, occurencies)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def buildcontextforUnivariate(self,target_series, occurencies):
    allvalues=[]
    vector = [0 for i in range(len(target_series))]
    pos = 0
    for i in range(len(target_series)):
        timestamp = target_series[i][1]
        current_pos = pos
        for q in range(pos, len(occurencies)):
            if occurencies[q][1] &gt; timestamp:
                current_pos = q
                break
        # no data found

        if current_pos == pos:
            # if no data in betwwen values use the previus value
            if i &gt; 0:
                vector[i] = vector[i - 1]
            # if no data until i timestamp use the first occurence as value
            else:
                vector[i] = occurencies[0][0]
        # if multiple values in between two timestamps use the mean of them as value
        else:
            dataInBetween = [value for value, time in occurencies[pos:current_pos]]
            vector[i] = sum(dataInBetween) / len(dataInBetween)
        # if no other occurencies just repeat the last value
        if current_pos == len(occurencies):
            for k in range(i + 1, len(vector)):
                vector[k] = vector[k - 1]
            break
        pos = current_pos

    return vector</code></pre>
</details>
</dd>
<dt id="PdmContext.ContextGeneration.ContextGenerator.buildcontextforisolated"><code class="name flex">
<span>def <span class="ident">buildcontextforisolated</span></span>(<span>self, target_series, occurencies)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def buildcontextforisolated(self,target_series, occurencies):
    vector = [0 for i in range(len(target_series))]
    for occ in occurencies:
        for q in range(len(target_series)):
            if target_series[q][1] &gt; occ[1]:
                vector[q] = 1
                break
    return vector</code></pre>
</details>
</dd>
<dt id="PdmContext.ContextGeneration.ContextGenerator.calculate_causality"><code class="name flex">
<span>def <span class="ident">calculate_causality</span></span>(<span>self, dataor, names)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_causality(self,dataor, names):
    num_time_series = len(dataor)
    data = np.array(dataor)
    edges=self.causality_discovery(names,data)
    #edges=self.calculatewithPc(names,data)
    #edges=self.calculatewith_fci(names,data)
    #edges=self.salesforcePC(names,data)
    return edges</code></pre>
</details>
</dd>
<dt id="PdmContext.ContextGeneration.ContextGenerator.calculate_edges"><code class="name flex">
<span>def <span class="ident">calculate_edges</span></span>(<span>self, alldata, timestamp)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_edges(self,alldata, timestamp):
    #start = time.time()
    storing = {}
    storing[&#34;timestamp&#34;] = timestamp

    alldata_names = [nn[0] for nn in alldata]
    alldata_data = [nn[1] for nn in alldata]

    for namedd, datadd in zip(alldata_names, alldata_data):
        storing[namedd] = datadd

    # For context with more than two series calculate PC casualities
    count = len([1 for lista in alldata_data if lista is not None])
    if count &gt; 1 and len(alldata[0][1]) &gt; 5:
        alldata_names = [nn[0] for nn in alldata if nn[1] is not None and len(set(nn[1]))&gt;1]
        alldata_data = [nn[1] for nn in alldata if nn[1] is not None and len(set(nn[1]))&gt;1]

        #end = time.time()
        #print(f&#34;before {end - start}&#34;)
        #start=time.time()

        edges = self.calculate_causality(np.column_stack(alldata_data), alldata_names)
        #end=time.time()
        #print(f&#34;actual edge calculation {end-start}&#34;)
        if edges is None:
            singleedges = []
        else:
            singleedges = edges
        # print(edges)
        storing[&#34;edges&#34;] = singleedges
        return storing
    storing[&#34;edges&#34;] = []
    return storing</code></pre>
</details>
</dd>
<dt id="PdmContext.ContextGeneration.ContextGenerator.collect_data"><code class="name flex">
<span>def <span class="ident">collect_data</span></span>(<span>self, timestamp, source, name, value=None, type='Univariate')</span>
</code></dt>
<dd>
<div class="desc"><p>This method is used when data are passed iteratively, and stored in buffer
When data of target source arrive, a corresponding context is produced.
Sources can be of different sample rate (all sources are mapped to the targets sample rate when context is produced)</p>
<p>Sources can be of either:</p>
<p>1) Continuous type (those that have some kind of arithmetic value)</p>
<p>2) Discrete events (without value) , where one of the type isolated or configuration must be assigned
A guide on how to specify the type is, that events which assumed to have impact only on their occurrence, are called
isolated, while others that are related to some kind of configuration with more permanent impact, are called configuration.
Essentially the type of the events define the way that will be transformed to real values time-series.</p>
<p><strong>Parameters</strong>:</p>
<p><strong>timestamp</strong>:
The timestamp of the arrived value</p>
<p><strong>source</strong>: The source of the arrived value</p>
<p><strong>name</strong>: The name (or identifier) of the arrived value</p>
<p><strong>value</strong>: The value (float), in case this is None the arrived data is considered as event</p>
<p><strong>type</strong>: the type of the data can be one of "isolated","configuration" when no value is passed</p>
<p><strong>return</strong>:
structure.Context object when the data name match to the target name or None.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def collect_data(self,timestamp,source,name,value=None,type=&#34;Univariate&#34;):
    &#39;&#39;&#39;
    This method is used when data are passed iteratively, and stored in buffer
    When data of target source arrive, a corresponding context is produced.
    Sources can be of different sample rate (all sources are mapped to the targets sample rate when context is produced)

    Sources can be of either:

    1) Continuous type (those that have some kind of arithmetic value)

    2) Discrete events (without value) , where one of the type isolated or configuration must be assigned
        A guide on how to specify the type is, that events which assumed to have impact only on their occurrence, are called
        isolated, while others that are related to some kind of configuration with more permanent impact, are called configuration.
        Essentially the type of the events define the way that will be transformed to real values time-series.

    **Parameters**:

    **timestamp**:  The timestamp of the arrived value

    **source**: The source of the arrived value

    **name**: The name (or identifier) of the arrived value

    **value**: The value (float), in case this is None the arrived data is considered as event

    **type**: the type of the data can be one of &#34;isolated&#34;,&#34;configuration&#34; when no value is passed

    **return**:  structure.Context object when the data name match to the target name or None.
    &#39;&#39;&#39;

    if value is None:
        if type not in [&#34;isolated&#34;,&#34;configuration&#34;]:
            assert False,&#34;The type must be defined as one of \&#34;isolated\&#34; and \&#34;configuration\&#34; when no value is passed&#34;
    eventpoint=Eventpoint(code=name,source=source,timestamp=timestamp,details=value,type=type)
    self.add_to_buffer(eventpoint)
    if self.target == name or self.target == f&#34;{name}@{source}&#34;:
        contextobject=self.generate_context(e=eventpoint,buffer=self.buffer)
        return contextobject
    else:
        return None</code></pre>
</details>
</dd>
<dt id="PdmContext.ContextGeneration.ContextGenerator.create_context"><code class="name flex">
<span>def <span class="ident">create_context</span></span>(<span>self, current: <a title="PdmContext.utils.structure.Eventpoint" href="utils/structure.html#PdmContext.utils.structure.Eventpoint">Eventpoint</a>, buffer)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_context(self,current :Eventpoint,buffer):

    #start = time.time()
    # df with ,dt,code,source,value
    pos=self.context_pos
    for i in range(pos,len(buffer)):
        if buffer[i].timestamp&lt;=(current.timestamp-pd.Timedelta(self.horizon, self.horizon_time)):
            pos=i
        else:
            break

    self.context_pos=pos
    #end=time.time()
    #print(f&#34;find position on buffer: {end-start}&#34;)

    #start = time.time()
    dataforcontext=buffer[pos:]
    datatodf=[[pd.to_datetime(e.timestamp) for e in dataforcontext],
            [str(e.code) for e in dataforcontext],
            [str(e.source) for e in dataforcontext],
            [e.details for e in dataforcontext],
            [e.type for e in dataforcontext]]

    npcontext=np.array(datatodf)
    npcontext=npcontext.T

    npcontext=self.Numpy_preproccess(npcontext)

    #end = time.time()
    #print(f&#34;preprocess df: {end - start}&#34;)
    ############# create context ############################
    #start = time.time()
    ## collect uniqeu data series
    #allcodes = df[&#39;code&#39;].unique()
    allcodes = np.unique(npcontext[:,1])
    allcodes = [code for code in allcodes]
    allcodes = set(allcodes)

    for uncode in allcodes:
        for qq in range(len(npcontext)):
            if uncode in npcontext[qq][1]:
                self.type_of_series[uncode]=npcontext[qq][4]
                break


    ## build target series
    target_series_name,target_series=self.build_target_series_for_context(current,npcontext)

    ## create series for each source (alldata)
    alldata=self.create_contius_representation(target_series_name,target_series,npcontext,self.type_of_series,allcodes)
    #end = time.time()
    #print(f&#34;Create series: {end-start}&#34;)

    storing = self.calculate_edges(alldata, current.timestamp)
    storing[&#34;characterization&#34;]=self.getcaracterize(storing)

    #print(f&#34;Calculate edges: {end - start}&#34;)
    # print(&#34;========================&#34;)


    contextpbject=Context.ContextFromDict(storing)
    return contextpbject,target_series_name</code></pre>
</details>
</dd>
<dt id="PdmContext.ContextGeneration.ContextGenerator.create_contius_representation"><code class="name flex">
<span>def <span class="ident">create_contius_representation</span></span>(<span>self, target_series_name, target_series, df, type_of_series, allcodes)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_contius_representation(self,target_series_name,target_series,df,type_of_series,allcodes):
    # if len(target_series) &lt; 5:
    #     alldata = []
    #     padding=[0 for q in range(5-len(target_series))]
    #     padding.extend([tags[0] for tags in target_series])
    #     alldata.append((target_series_name, padding))
    #     return alldata
    windowvalues = df#.values
    alldata = []
    alldata.append((target_series_name, [tag[0] for tag in target_series]))
    for name in allcodes:
        # already calculated in targetseries.
        if target_series_name in name:
            continue

        # detect the occurancies
        occurencies = [(value, time) for code, value, time in
                       zip(windowvalues[:, 1], windowvalues[:, 3], windowvalues[:, 0]) if name in code]

        vector = [0 for i in range(len(target_series))]
        if len(occurencies) == 0:
            vector = [0 for i in range(len(target_series))]
        elif occurencies[0][0] is not None:
            vector = self.buildcontextforUnivariate(target_series, occurencies)
        elif type_of_series[name] == &#34;isolated&#34;:
            vector = self.buildcontextforisolated(target_series, occurencies)
        elif type_of_series[name] == &#34;configuration&#34;:
            vector = self.buildcontextforCOnfiuguration(target_series, occurencies)

        ok = &#34;ok&#34;
        # if vector is stationary then no context.
        if max(vector) == 0 and min(vector) == 0:
            vector = None
        alldata.append((name, vector))
    return alldata</code></pre>
</details>
</dd>
<dt id="PdmContext.ContextGeneration.ContextGenerator.create_interpertation"><code class="name flex">
<span>def <span class="ident">create_interpertation</span></span>(<span>self, contextcurrent: <a title="PdmContext.utils.structure.Context" href="utils/structure.html#PdmContext.utils.structure.Context">Context</a>, target_series_name)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_interpertation(self,contextcurrent :Context,target_series_name):
    rikicontext=self.contexts
    pos=self.interpret_history_pos
    temppos=pos
    for q in range(pos,len(rikicontext)):
        temppos=q
        if pd.to_datetime(rikicontext[q].timestamp) &gt;= (pd.to_datetime(contextcurrent.timestamp) - pd.Timedelta(self.horizon, self.horizon_time)):
            break
    causeswindow = rikicontext[temppos:]
    self.interpret_history_pos=temppos
    interpr=self.interpret(contextcurrent,causeswindow,target_series_name,self.type_of_series)
    self.contexts[-1].CR[&#34;interpertation&#34;]=interpr</code></pre>
</details>
</dd>
<dt id="PdmContext.ContextGeneration.ContextGenerator.generate_context"><code class="name flex">
<span>def <span class="ident">generate_context</span></span>(<span>self, e: <a title="PdmContext.utils.structure.Eventpoint" href="utils/structure.html#PdmContext.utils.structure.Eventpoint">Eventpoint</a>, buffer)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_context(self,e:Eventpoint,buffer):
    contextcurrent, target_series_name = self.create_context(e,buffer)

    self.contexts.append(contextcurrent)
    self.create_interpertation(contextcurrent, target_series_name)


    intertups = [tttup for tttup in
                 self.contexts[-1].CR[&#34;interpertation&#34;]]
    # this is usefull for ploting
    self.contexts[-1].CR[&#34;interpertation&#34;] = intertups

    return self.contexts[-1]</code></pre>
</details>
</dd>
<dt id="PdmContext.ContextGeneration.ContextGenerator.getcaracterize"><code class="name flex">
<span>def <span class="ident">getcaracterize</span></span>(<span>self, context)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def getcaracterize(self,context):
    edges = context[&#34;edges&#34;]
    characterizations = []
    for edge in edges:
        name1 = edge[0]
        name2 = edge[1]
        values1 = context[name1]
        values2 = [float(kati) for kati in context[name2]]

        occurence=len(values1)-1
        for i in range(len(values1)-2,0,-1):
            if values1[i] != values1[-1]:
                occurence = i+1
                break
        previusoccurence = 0
        for i in range(occurence-2,0,-1):
            if values1[i] !=  values1[occurence-1]:
                previusoccurence = i

        if occurence - previusoccurence &lt; 2:  # or len(values2)-occurence&lt;2:
            characterizations.append(&#34;uknown&#34;)
            continue
        values2before = values2[previusoccurence:occurence]
        # stdv = statistics.stdev(values2before)
        # mean = statistics.stdev(values2before)
        # values2before=[v if v&lt;mean+5*stdv else mean for v in values2before]

        # values2after=values2[occurence:]
        values2after = [values2[-1]]
        # stdv = statistics.stdev(values2after)
        # mean = statistics.stdev(values2after)
        # values2after = [v if v &lt; mean + 3 * stdv else mean for v in values2after]

        stdv = statistics.stdev(values2before)
        if len(values2before) == 0:
            char = &#34;uknown&#34;
        elif statistics.median(values2before) - statistics.median(values2after) &gt; 2 * stdv:
            char = &#34;decrease&#34;
        elif statistics.median(values2after) - statistics.median(values2before) &gt; 2 * stdv:
            char = &#34;increase&#34;
        else:
            char = &#34;uknown&#34;
        characterizations.append(char)
    return characterizations</code></pre>
</details>
</dd>
<dt id="PdmContext.ContextGeneration.ContextGenerator.interpret"><code class="name flex">
<span>def <span class="ident">interpret</span></span>(<span>self, context: <a title="PdmContext.utils.structure.Context" href="utils/structure.html#PdmContext.utils.structure.Context">Context</a>, causeswindow, target, type_of_series)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def interpret(self,context : Context, causeswindow, target, type_of_series):
    pairs = [(pair[0], pair[1], car) for pair, car in zip(context.CR[&#39;edges&#39;], context.CR[&#39;characterization&#39;]) if
             target in pair[1]]
    interpretation = []
    if len(pairs) == 0:
        return []
    for pair in pairs:
        if type_of_series[pair[0]] == &#34;isolated&#34;:
            values1 = context.CD[pair[0]]
            if values1[-1] == 1:
                interpretation.append(pair)
            elif values1[-2] == 1:
                interpretation.append(pair)
        elif type_of_series[pair[0]] == &#34;configuration&#34;:
            if pair[0] == &#34;weld@press&#34; and pair[2] == &#34;increase&#34;:
                ok = &#34;ok&#34;
            values1 = context.CD[pair[0]]
            occurence = 0
            for q in range(len(values1)):
                if values1[q] == values1[-1] and values1[q] &gt; 0:
                    occurence = q
                    break
            if occurence == len(values1) - 1:
                interpretation.append(pair)
            else:
                lead = len(values1) - occurence
                counter = 0
                leadcontext = causeswindow[-lead:]
                for conte in leadcontext:
                    try:
                        pos = list(conte.CR[&#34;edges&#34;]).index((pair[0], pair[1]))
                    except:
                        pos = -1
                    if pos != -1:
                        if conte.CR[&#34;characterization&#34;][pos] == pair[2]:
                            counter += 1
                if counter &gt;= 0.8 * lead:
                    interpretation.append(pair)
        # for real value series
        if len(set(context.CD[pair[0]])) &gt; 2:
            interpretation.append(pair)
            continue
    # check target -&gt; isolated
    pairs = [(pair[0], pair[1], car) for pair, car in zip(context.CR[&#39;edges&#39;], context.CR[&#39;characterization&#39;]) if
             target in pair[0] and type_of_series[pair[1]] == &#34;isolated&#34;]
    # for pair in pairs:
    #     if type_of_series[pair[1]] == &#34;isolated&#34;:
    #         values1 = context.CD[pair[1]]
    #         if values1[-1] == 1 or values1[-2] == 1:
    #             interpretation.append((pair[1],pair[0],pair[2]))
    return list(set(interpretation))</code></pre>
</details>
</dd>
<dt id="PdmContext.ContextGeneration.ContextGenerator.plot"><code class="name flex">
<span>def <span class="ident">plot</span></span>(<span>self, filteredges=[['', '', '']])</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot(self,filteredges=[[&#34;&#34;, &#34;&#34;, &#34;&#34;]]):
    show_Context_list(self.contexts,self.target,filteredges=filteredges)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="PdmContext" href="index.html">PdmContext</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="PdmContext.ContextGeneration.ContextGenerator" href="#PdmContext.ContextGeneration.ContextGenerator">ContextGenerator</a></code></h4>
<ul class="">
<li><code><a title="PdmContext.ContextGeneration.ContextGenerator.Numpy_preproccess" href="#PdmContext.ContextGeneration.ContextGenerator.Numpy_preproccess">Numpy_preproccess</a></code></li>
<li><code><a title="PdmContext.ContextGeneration.ContextGenerator.add_to_buffer" href="#PdmContext.ContextGeneration.ContextGenerator.add_to_buffer">add_to_buffer</a></code></li>
<li><code><a title="PdmContext.ContextGeneration.ContextGenerator.build_target_series_for_context" href="#PdmContext.ContextGeneration.ContextGenerator.build_target_series_for_context">build_target_series_for_context</a></code></li>
<li><code><a title="PdmContext.ContextGeneration.ContextGenerator.buildcontextforCOnfiuguration" href="#PdmContext.ContextGeneration.ContextGenerator.buildcontextforCOnfiuguration">buildcontextforCOnfiuguration</a></code></li>
<li><code><a title="PdmContext.ContextGeneration.ContextGenerator.buildcontextforUnivariate" href="#PdmContext.ContextGeneration.ContextGenerator.buildcontextforUnivariate">buildcontextforUnivariate</a></code></li>
<li><code><a title="PdmContext.ContextGeneration.ContextGenerator.buildcontextforisolated" href="#PdmContext.ContextGeneration.ContextGenerator.buildcontextforisolated">buildcontextforisolated</a></code></li>
<li><code><a title="PdmContext.ContextGeneration.ContextGenerator.calculate_causality" href="#PdmContext.ContextGeneration.ContextGenerator.calculate_causality">calculate_causality</a></code></li>
<li><code><a title="PdmContext.ContextGeneration.ContextGenerator.calculate_edges" href="#PdmContext.ContextGeneration.ContextGenerator.calculate_edges">calculate_edges</a></code></li>
<li><code><a title="PdmContext.ContextGeneration.ContextGenerator.collect_data" href="#PdmContext.ContextGeneration.ContextGenerator.collect_data">collect_data</a></code></li>
<li><code><a title="PdmContext.ContextGeneration.ContextGenerator.create_context" href="#PdmContext.ContextGeneration.ContextGenerator.create_context">create_context</a></code></li>
<li><code><a title="PdmContext.ContextGeneration.ContextGenerator.create_contius_representation" href="#PdmContext.ContextGeneration.ContextGenerator.create_contius_representation">create_contius_representation</a></code></li>
<li><code><a title="PdmContext.ContextGeneration.ContextGenerator.create_interpertation" href="#PdmContext.ContextGeneration.ContextGenerator.create_interpertation">create_interpertation</a></code></li>
<li><code><a title="PdmContext.ContextGeneration.ContextGenerator.generate_context" href="#PdmContext.ContextGeneration.ContextGenerator.generate_context">generate_context</a></code></li>
<li><code><a title="PdmContext.ContextGeneration.ContextGenerator.getcaracterize" href="#PdmContext.ContextGeneration.ContextGenerator.getcaracterize">getcaracterize</a></code></li>
<li><code><a title="PdmContext.ContextGeneration.ContextGenerator.interpret" href="#PdmContext.ContextGeneration.ContextGenerator.interpret">interpret</a></code></li>
<li><code><a title="PdmContext.ContextGeneration.ContextGenerator.plot" href="#PdmContext.ContextGeneration.ContextGenerator.plot">plot</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>